<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>태그: hadoop - 기술블로그</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="기술블로그"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="기술블로그"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="기술블로그"><meta property="og:url" content="https://tk-one.github.io/"><meta property="og:site_name" content="기술블로그"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://tk-one.github.io/img/og_image.png"><meta property="article:author" content="TK-one"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://tk-one.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://tk-one.github.io"},"headline":"기술블로그","image":["https://tk-one.github.io/img/og_image.png"],"author":{"@type":"Person","name":"TK-one"},"publisher":{"@type":"Organization","name":"기술블로그","logo":{"@type":"ImageObject","url":"https://tk-one.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/androidstudio.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-124797892-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-124797892-1');</script><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/rss2.xml" title="기술블로그" type="application/rss+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="기술블로그" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">hadoop</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-06-19T13:29:02.000Z" title="19/06/2022, 22:29:02">2022-06-19</time>&nbsp;게시 됨</span><span class="level-item"><a class="link-muted" href="/categories/Hadoop/">Hadoop</a></span><span class="level-item">12분안에 읽기 (약 1732 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/06/19/hadoop-file-based-data-structure/">Hadoop 파일기반 자료구조(SequenceFile, MapFile)</a></h1><div class="content"><p>이번 글에서는 Hadoop에서 지원하는 파일저장시 지원하는 자료구조 2가지를 알아본다.<br>파일에 데이터를 저장시 그냥 blob 전체를 한개의 파일에 그대로 몽땅 저장하는 방식을 생각해보자. 그러면 파일의 내용은 block 크기로 잘라져 논리적으로 연속된 block으로 보일 것이다. 다만 이런 방식이면 경우에 따라 확장성에 좋지 않을 수 있다.<br>따라서 다양한 상황을 위해 Hadoop은 여러 파일 기반의 자료구조를 지원한다. 즉 스토리지에 저장시에 고려하는 자료구조이다.<br>여기서 볼 자료구조는 <strong>SequenceFile</strong>과 <strong>MapFile</strong>이다.  </p>
<br/>

<h2 id="SequenceFile"><a href="#SequenceFile" class="headerlink" title="SequenceFile"></a>SequenceFile</h2><p>SequenceFile은 로그파일과 잘맞는다. 로그파일은 record 한개당 하나의 행이다. 이런 로그파일을 그냥 binary로 저장하는것은 이후에 이 로그파일을 기반으로 무언가 작업을 할 예정이라면 확장성이 없는 방식이다.<br>Hadoop에서 제공하는 SequenceFile은 이런 형식의 데이터를 저장하기에 적절하다. SequenceFile은 binary key-value 쌍에 대한 storage-level의 자료구조를 제공한다.<br>예를들어 로그의 포맷이라면 key를 Hadoop의 <code>LongWritable</code>로 표현되는 timestamp로, value를 로그의 내용으로 저장할 수 있겠다.  </p>
<h4 id="SequenceFile-format"><a href="#SequenceFile-format" class="headerlink" title="SequenceFile format"></a>SequenceFile format</h4><p>SequenceFile의 포맷을 조금 더 자세히 보자. SequenceFile의 대략적인 내부구조는 다음과 같다.  </p>
<p align="center">
    <img alt="SequenceFile format" style="max-width: 700px;" src="/images/hadoop/sequencefile.png"/>
</p>

<p>맨앞에는 header가 오고 그 뒤에는 하나이상의 record들이 위치한다. header에는 key, value 클래스의 이름, 압축이 되어있다면 압축관련정보 그리고 sync marker등이 존재한다.<br>SequenceFile에서는 <strong>sync point</strong>라는 것이 존재한다. SequenceFile에 write 할때 몇개의 record 단위마다 sync point를 marking 해놓는다. 이 sync point는 반드시 record 경계에 맞추어진다.<br>이 sync point는 reader가 record 경계를 잃어버렸을때 record 경계를 다시 동기화 하는데에 사용할 수 있다. 예를들어 파일의 위치가 record 경계에 있지 않으면 reader의 읽기 메서드가 예외를 반환한다. 이런 경우에 <code>SequenceFile.Reader</code>의 <code>sync(long position)</code> 메서드를 호출하면 position 이후의 바로 다음 sync point로 read point를 이동시켜준다. 그러므로 그 다음부터는 읽기를 다시 정상적으로 수행할 수 있다.<br>위 그림에서도 몇개의 record 단위마다 sync point가 저장되어있는 것을 확인할 수 있다.<br>각 SequenceFile은 랜덤하게 생성된 sync marker가 있고 이 값이 header에 존재한다. 그리고 이 sync marker가 위에서 본 sync point 마다 값이 저장되어 있는것이다.  </p>
<p>이제 record는 내부구조가 어떤지 살펴보자.<br>만약 record가 압축되어있지 않다면 각 record 들은 위의 그림과 같이 byte 단위의 record length, key length, key, value로 구성된다.<br>record가 압축이 되어있는 경우는 압축하지 않은 경우와 거의 동일하지만 value가 header에 명시된 codec으로 압축된 binary 인 점만 다르다.  </p>
<p>여러개의 record을 모아 block을 구성하고 이 block을 압축하는 방식도 있다. 여러개의 record로 구성된 block 자체를 압축하므로 record 단위 압축보다 압축도가 높고 가까이 있는 record 간에 유사성이 높으므로 효율도 더 좋을 수 있어 record 단위의 압축보다는 block 단위 압축방식이 더 선호된다.<br>record들은 <code>io.seqfile.compress.blocksize</code> 설정값에 정의된 크기에 이를때까지 하나의 block에 계속 추가된다. 이 설정의 기본값은 1MB이다.<br>Block compression 방식의 내부구조는 다음과 같다.  </p>
<p align="center">
    <img alt="SequenceFile Block compression" style="max-width: 700px;" src="/images/hadoop/sequencefile-block-compression.png"/>
</p>

<p>이 SequenceFile은 대용량 dataset에 적합하다. 효율적으로 대용량 dataset을 처리하는데 효율적으로 설계되었으며, 각 SequenceFile 의 부분들을 병렬로 처리하도록 설계할 수도 있다. 또 파일의 순차접근에 강하며 파일을 저장할때 그냥 binary format으로 저장하기 때문에 매우 심플하고 다른언어에서도 이를 쉽게 다룰 수 있다.  </p>
<p>다만, <code>Parquet</code> 이나 <code>ORC</code> 같은 포맷에 비해서는 공간효율적이지는 못하다. 그리고 random access 를 위해 설게된 것은 아니기에, random access 가 자주 사용되는 애플리케이션에서는 SequenceFile이 비효율적 일 수 있다. 그리고 schema 변화를 제한적으로만 지원하기 때문에 데이터 구조를 변경하는 것이 힘들다.  </p>
<br/>

<h2 id="MapFile"><a href="#MapFile" class="headerlink" title="MapFile"></a>MapFile</h2><p>MapFile은 key를 기준으로 정렬이 되어있는 SequenceFile이다. 앞에서 본 SequenceFile은 record들이 정렬되어있을 필요는 없었다. 다만 MapFile은 반드시 record 들이 key 기준으로 정렬되어있어야 한다. 그리고 MapFile은 index를 통해 key로 record를 빠르게 검색할 수 있다.<br>MapFile을 생성하게 되면 directory가 생성되고 이 내부에 data 파일과 index 파일이 각각 존재한다. 여기서의 data 파일과 index 파일 모두 SequenceFile이다. data 파일은 key로 <strong>정렬된 record</strong>들로 구성되어 있으며 index 파일도 내부에 key들의 fragment들을 포함하고 있는 SequenceFile이다.<br>index는 기본적으로 data record의 128번째마다 key를 저장해둔다.  </p>
<p>MapFile에서 key 검색을 위해서는 index를 메모리에 올려 index를 기준으로 data record의 위치를 찾는다.<br>MapFile은 SequenceFile과 조금 다르게 파일에 쓸때에는 반드시 key로 정렬된 순서로 write해야한다. 그렇지 않으면 예외가 발생한다.  </p>
<br/>

<h2 id="Other-File-format"><a href="#Other-File-format" class="headerlink" title="Other File format"></a>Other File format</h2><p>Hadoop은 SequenceFile과 MapFile 말고도 다른 새로운 파일포맷도 많이 제공한다. SequenceFile, MapFile은 모두 row 기반의 파일포맷이지만 이 방식 말고도 column 기반의 파일포맷도 존재한다.<br>column 기반의 파일포맷에서는 각 row를 컬럼기준으로 나누어 저장한다. 예를들어 다음 그림처럼 첫번째 column이 먼저 저장되고, 그 다음 column이 저장되는 방식이다.  </p>
<p align="center">
    <img alt="Column based file format" style="max-width: 700px;" src="/images/hadoop/column-based-file-format.png"/>
</p>

<p>만약 이 data들이 table의 데이터고 table에서 특정 column만 쿼리하는 과정을 생각해보자. 기존의 row 기반의 파일포맷은 관련있는 row를 모두 읽어 메모리로 읽어들인 후에 이들을 역직렬화하여 column을 뽑아내야한다.<br>하지만 column based 파일포맷은 직접 필요한 소수의 column만 읽어들일 수 있는 장점이 있다.  </p>
<br/>

<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Hadoop-Perfect-Guide-Korean-White/dp/8968484597">https://www.amazon.com/Hadoop-Perfect-Guide-Korean-White/dp/8968484597</a></li>
</ul>
<br/>
<br/>
<br/>






</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-06-18T13:29:02.000Z" title="18/06/2022, 22:29:02">2022-06-18</time>&nbsp;게시 됨</span><span class="level-item"><a class="link-muted" href="/categories/Hadoop/">Hadoop</a></span><span class="level-item">한 시간안에 읽기 (약 7104 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/06/18/hbase/">HBase 기초</a></h1><div class="content"><br/>

<h2 id="HBase-Data-Model"><a href="#HBase-Data-Model" class="headerlink" title="HBase Data Model"></a>HBase Data Model</h2><p>HBase의 데이터 모델부터 보도록 하자.  </p>
<h4 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h4><p>HBase는 데이터들을 table안에 구성한다. table 이름은 String으로 파일시스템 path로 사용하는데 문제없도록 구성한다.  </p>
<h4 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h4><p>Table 안에서 데이터는 table의 row에 따라 저장된다. Row는 rowkey에 의해 유일하게 식별되고 rowkey는 다른 data type을 가지지 않고 <code>byte[]</code>로 구성된다. 한개의 Row는 한개 혹은 여러개의 record로 구성된다.  </p>
<h4 id="Column-Family"><a href="#Column-Family" class="headerlink" title="Column Family"></a>Column Family</h4><p>HBase에서의 column들은 <strong>Column Family</strong> 라고 부르는 일종의 그룹에 속한다.<br>HBase의 테이블은 최소한 한 개 이상의 column family를 가져야 한다.<br>Row의 record들은 column family로 그룹화된다. Column Family는 중요한데 HBase에서 데이터 저장에 있어 물리적인 특성과 관련이 깊다. 각 column family 마다 storage 관련 속성(caching 여부, 압축여부 등)을 지정할 수 있다.  </p>
<h4 id="Column-Qualifier"><a href="#Column-Qualifier" class="headerlink" title="Column Qualifier"></a>Column Qualifier</h4><p>column family 안의 데이터들은 column qualifier를 통해 표현된다. 만약 column family가 <code>info</code> 라면 column qualifier는 <code>info:name</code> 나 <code>info:email</code> 등이 될 수 있겠다. column qualifier는 미리 정의되어있을 필요가 없으며 각 row들마다 일관성없이 다른 column qualifier들을 가질 수 있다.<br>Column Qualifier은 그냥 column 이라고도 불리고 qual 이라고도 불린다.  </p>
<h4 id="Cell"><a href="#Cell" class="headerlink" title="Cell"></a>Cell</h4><p>Cell은 rowkey, column family, column qualifier의 조합이다. 이 조합이 cell을 식별한다. 이 cell에는 value로 데이터가 저장되어있고 version을 의미하는 timestamp도 포함한다.  </p>
<h4 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h4><p>Cell 내부의 value들은 version 별로 저장이 된다. version은 long 타입의 timestamp이며 이 값을 따로 지정하지 않으면 현재 timestamp 값으로 설정된다. HBase에서 각 column family 마다 cell 마다 유지되는 version 개수를 설정할 수 있으며 기본값은 <code>3</code>이다.    </p>
<br/>
위의 6가지 개념에 대해 이해한다면 앞으로 HBase를 이해하는데 크게 도움이 된다. 다음 그림을 보자.  

<p align="center">
    <img alt="HBase Data Model Example" src="/images/hadoop/hbase-schema.png"/>
</p>

<p>각 row는 한개 이상의 cell들로 구성되어있고 각 row는 rowkey를 기준으로 정렬되어있다.<br>각 cell에는 여러개의 version이 저장되어 있는 것도 확인할 수 있다.  </p>
<br/>

<h4 id="Cell-Coordinate"><a href="#Cell-Coordinate" class="headerlink" title="Cell Coordinate"></a>Cell Coordinate</h4><p>HBase에서 cell 값은 <strong>coordinate</strong>에 의해 접근된다. 말 그대로 좌표라는 의미이다. coordinate는 rowkey, column family, column qualifier 순서의 조합이다.<br>논리적인 그림으로 생각했을때에 결국 HBase는 coordinate를 key로 각 coordinate의 데이터를 value로 가진 key-value 저장소로 생각할 수 있다.<br>HBase에서 데이터를 얻기위해 <code>Get</code> 요청을 할때 coordinate 정보 전체를 제공하지 않아도 된다. 만약 rowkey, column family, column qualifier로 요청한다면 version 별 map을 결과로 얻을 수 있다.  </p>
<h4 id="Cell-Key"><a href="#Cell-Key" class="headerlink" title="Cell Key"></a>Cell Key</h4><p>HBase에서 cell key는 rowkey, column family, column qualifier, version 의 조합이다. 밑에서 보게되겠지만 HBase는 HFile 이라는 형식으로 데이터를 저장하는데 HBase의 cell key는 이 HFile의 key 이고 이 cell key로 정렬이 되어있다.  </p>
<br/>

<p>HBase는 엄격한 데이터 규칙이 없는 semi-structured 데이터들을 위해 설계되었다. 이런 semi-structured 논리 모델로 데이터들은 각 데이터 컴포넌트들 간의 느슨한 연결을 가지도록 하고 이런 구조로 물리적으로 scale을 쉽게 해준다.<br>애초에 HBase는 scale을 염두에 두고 설계되었고 이런 결정이 물리모델에 영향을 끼치고 있다. 다만 이런 물리적 모델 특성으로 RDBMS에서 제공하는 multirow transaction을 지원하지 못한다. 밑에서 HBase의 논리적 모델과 물리적 모델을 살펴보자.  </p>
<h4 id="Logical-Model"><a href="#Logical-Model" class="headerlink" title="Logical Model"></a>Logical Model</h4><p>HBase가 논리적으로는 어떤 모델을 가지고 있는지 이해하면 HBase를 쉽게 이해할 수 있다.<br>HBase는 맵들의 정렬된 맵(sorted map of maps)이라고 바라볼 수 있다. 먼저 다음 그림을 보며 이해해보자.  </p>
<p align="center">
    <img alt="HBase map 들의 sorted map" src="/images/hadoop/hbase-sorted-map.png"/>
</p>

<p>이처럼 논리적으로 데이터를 map 구조로 표현할 수 있다. 이는 “TheRealMT” 라는 rowkey의 데이터를 가지고 온 내용이다.<br>Map을 자세히 보면 map의 가장 안쪽에서는 cell의 version이 key이고 저장된 데이터가 value이다. 그 한단계 위에서는 column qualifier가 key이고 cell이 value이다. 결국 이를 자바로 표현하면 이와 같을 것이다.<br><code>Map&lt;RowKey, Map&lt;ColumnFamily, Map&lt;ColumnQualifier, Map&lt;Version, Data&gt;&gt;&gt;&gt;</code></p>
<p>또하나 주목할 점은 sorted map이라는 것은 key로 정렬되어있다는 것이다. 위 예제에 password는 2가지 version이 존재하는데 항상 새로운 version이 더 앞에오도록 정렬되어있다. HBase는 내림차순으로 version timestamp을 정렬한다. 그러므로 최근 version에 대한 빠른 접근을 가능하게 한다. version이 아닌 다른 key들은 모두 오름차순으로 정렬되어있는 것을 확인할 수 있다. 이런 특징은 schema 설계시 매우 중요하다.  </p>
<br/>

<h4 id="Physical-Model"><a href="#Physical-Model" class="headerlink" title="Physical Model"></a>Physical Model</h4><p>HBase는 HFile에 key-value 형식으로 저장이 된다. 위에서 보았던 “TheRealMT” 라는 rowkey를 가진 데이터는 다음과 같이 HFile에 저장된다.  </p>
<p align="center">
    <img src="/images/hadoop/hbase-physical-hfile.png"/>
</p>

<p>이처럼 row 1개는 HFile 안에서 여러개의 record로 이루어져 있다. 또한 사용되지 않거나 null인 record가 없다. HBase는 데이터가 없을시에는 아예 아무것도 저장하지 않는다.<br>또 한가지 주목할 점은 HFile은 column family 별로 따로 생성된다. 하지만 같은 column family를 가진 single row도 동일한 HFile에 같이 존재하지 않을 수 있다. 이미 존재하는 rowkey에 새로운 column qualifier로 데이터를 넣는과정을 예시로 들 수 있겠다. 그러므로 single row 전체를 다 읽으려면 모든 HFile을 다 확인해야한다.<br>각 column family 별로 별도의 HFile을 사용하므로 HBase는 read 수행시 요청된 column family에 해당하는 HFile들만 읽으면 된다. 이런 물리적인 특성들은 storage를 더 효율적으로 사용하고 빠른 읽기를 가능하게 한다.  </p>
<p align="center">
    <img src="/images/hadoop/hbase-hfile-per-cf.png"/>
</p>

<p>위 그림처럼 새로운 column family인 “activity”를 추가했다고 해보자. 이는 더 많은 HFile을 만들어내고 기존의 “info” column family와는 격리되어있고 전혀 다른 HFile을 만들어 내고있다. activity column family 내의 데이터가 커져도 info column family 성능에는 영향을 주지 않는다.  </p>
<br/>

<h2 id="Data-in-HBase"><a href="#Data-in-HBase" class="headerlink" title="Data in HBase"></a>Data in HBase</h2><p>HBase 테이블의 모든 row는 <strong>rowkey</strong>라는 유일한 식별자를 가지고 있다. 이는 테이블 내에서 유일한 값이다.<br>HBase에 저장된 모든 데이터들은 byte array 형태의 raw data로 저장된다. 자바 클라이언트 라이브러리에서는 이를 위해 <code>Bytes</code> 클래스를 제공해 다양한 형태의 데이터를 byte array로 바꿀 수 있다.  </p>
<p>위에서 보았듯이 cell은 [rowkey, column family, column qualifier] 좌표로 결정된다. 밑의 예제를 한번 보자.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Put</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Put</span>(Bytes.toBytes(<span class="hljs-string">&quot;TK-one&quot;</span>);<br>p.add(Bytes.toBytes(<span class="hljs-string">&quot;info&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;name&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;Jin Hyuk&quot;</span>));<br>p.add(Bytes.toBytes(<span class="hljs-string">&quot;info&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;email&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;email@email.com&quot;</span>));<br>p.add(Bytes.toBytes(<span class="hljs-string">&quot;info&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;password&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;pwd&quot;</span>));<br></code></pre></td></tr></table></figure>
<p>여기서 <code>Put</code> 객체를 만들었는데 이는 새로운 data를 저장할때나 기존에 존재하는 row를 수정할때 사용한다.<br>여기서는 info라는 column family에 속한 name, email, password라는 column에 값을 설정했다. 이름을 저장하고 있는 cell의 coordinates는 [TK-one, info, name] 이다. </p>
<br/>

<h2 id="HBase-write"><a href="#HBase-write" class="headerlink" title="HBase write"></a>HBase write</h2><p>새로운 row를 만들때나 기존 row를 수정할때나 내부 프로세스는 동일하다.<br>HBase는 command를 받으면 변경사항을 저장하고 만약 저장에 실패했으면 예외를 발생시킨다. 변경사항을 저장할때 기본적으로 두곳에 변경사항을 저장한다.<br>첫번째는 <strong>WAL</strong>(<strong>Write Ahead Log</strong>)에 저장한다. 이는 <strong>HLog</strong>라고도 불린다. 두번째는 <strong>MemStore</strong>에 저장한다.<br>HBase는 기본적으로 data의 내구성을 위해 두곳에 모두 저장한다. 두곳에 모두 저장해야 write가 완료된다.  </p>
<p align="center">
    <img alt="write in HBase" style="max-width: 500px;" src="/images/hadoop/hbase-write.png"/>
</p>

<p>Memstore는 HBase에서 disk에 write하기 전에 HBase 메모리에 데이터를 모아놓은 buffer이다. 나중에 Memstore가 가득차게되면 <strong>HFile</strong>이라는 형태로 disk에 flush된다. 이미 존재하는 HFile에 append하는게 아니라 매 flush 마다 새로운 파일을 만든다. 여기서의 HFile은 HBase에서 사용하는 storage용 format이라고 생각하면 좋다.<br>HFile은 1개의 column family에 속해있다. 즉 하나의 HFile은 여러개의 column family로 이루어진 데이터를 가질 수 없다. Column family 당 1 개의 Memstore를 가지고 각 Memstore들은 가득차면 HFile로 flush 된다. 이 HFile도 HDFS에 저장된다.  </p>
<p align="center">
    <img alt="Memstore per column family" style="max-width: 300px;" src="/images/hadoop/hbase-memstore.png"/>
</p>

<p>HBase에도 장애가 발생할 수 있다. 만약 서버가 다운되어 in-memory data를 모두 잃었을때는 아직 flush되지 않은 Memstore의 내용은 모두 유실될 것이다. HBase는 write 시에 WAL(Write Ahead Log)에 data를 write 하기때문에 이 WAL를 다시 replay 함으로서 MemStore 내용을 복구할 수 있다. HBase는 모든 변경사항을 WAL에 쓴다. 그리고 HBase는 이 WAL을 HDFS에 쓴다.<br>HBase의 Region 서버가 다운되어도 WAL을 HDFS에 썼다면 replica 3개중 아무곳에서 데이터를 제공받아 recover 할수있다. 만약 WAL이 Region 서버의 local disk에만 제공된다면 data loss가 발생할 수 있으므로 HDFS에 write 한다.<br>이 말고도 HDFS는 HBase Region 서버들에게 단일 namespace 파일시스템으로서 역할을 하기때문에 모든 Region 서버들은 다른 Region 서버들이 쓴 데이터들을 모두 볼 수 있다. 그러므로 Region 서버 장애시 다른 Region 서버에서 손쉽게 해당 WAL을 읽어 복구가 가능하다. 그러므로 Region 서버의 설계자체를 조금 더 간단하게 할 수 있는 장점이 있다.  </p>
<p>WAL에 recording이 성공해야 write operation 이 성공했다고 간주한다.<br>WAL은 HBase 서버당 한개씩 존재하고 그 서버의 모든 table들이 이를 공유한다.  </p>
<br/>

<h2 id="HFile"><a href="#HFile" class="headerlink" title="HFile"></a>HFile</h2><p>HBase는 random access를 지원한다. HDFS 위에서 어떻게 이를 가능하게 할까? 이를 위해서는 <strong>HFile</strong>를 이해해야한다.<br>먼저 HFile을 알아보기 전에 Hadoop의 파일기반 자료구조인 SequenceFile과 MapFile에 대한 개념이 있어야한다. 해당 내용은 <a href="/2022/06/19/hadoop-file-based-data-structure/">Hadoop 파일기반 자료구조(SequenceFile, MapFile)</a>에 정리해놓았다.  </p>
<p>HBase 버전 0.20 이전까지는 데이터를 저장하는데 Hadoop의 <strong>MapFile</strong>을 사용했다. MapFile은 SequenceFile의 확장판으로 data 파일과 index 파일을 포함하고 있는 디렉토리이다. MapFile의 데이터는 key를 기준으로 정렬된 key-value 데이터이고 매 구간의 key를 index에  offset과 함께 저장해놓음으로서 index scan만 함으로서 fast lookup을 가능하게 한다.  </p>
<h6 id="HBase-with-MapFile"><a href="#HBase-with-MapFile" class="headerlink" title="HBase with MapFile"></a>HBase with MapFile</h6><p>초기버전의 HBase는 MapFile을 사용했는데 key로는 rowkey, column family, column qualifier, timestamp, type으로 구성했다. value로는 row 내용이 들어갈 것이다.  </p>
<p align="center">
    <img alt="HBase with MapFile" style="max-width: 600px;" src="/images/hadoop/hbase-with-mapfile.png"/>
</p>
  
<p>여기서의 type은 해당 row가 삭제되었는지를 나타내는 flag인데 이는 밑에서 자세히 알아볼 것이다.<br>위와같이 MapFile을 구성하면 만약 row를 수정하면 어떻게 다음 조회에 수정된 내용을 반환할 수 있을까? 같은 row중 더 큰 timestamp를 가진 row를 반환할 수 있겠다.<br>MapFile에서의 data 파일은 반드시 key로 정렬이 되어있어야 한다. 하지만 HBase에 write하는 데이터는 정렬된 순서로 도착하지 않는다. 이를 해결하기 위해 위에서 보았듯이 HBase는 write command시 MemStore에 데이터를 저장하고 있다가 가득차면 flush 한다. MemStore는 <code>ConcurrentSkipListMap</code>과 동일하므로 이미 key로 정렬되어있다. 이를 MapFile로 flush하고 해당 MapFile은 더이상 수정하지 않는다. 그러므로 데이터를 찾을때에는 모든 MapFile을 대상으로 검색해야한다. 이는 성능에 좋지않으므로 성능을 개선하는 방법을 밑에서 자세히 알아볼 것이다.  </p>
<h6 id="HFile-version-1"><a href="#HFile-version-1" class="headerlink" title="HFile version 1"></a>HFile version 1</h6><p>HBase 0.20 버전부터 HBase는 MapFile을 사용하지 않고 직접 구현한 MapFile과 비슷한 <strong>HFile</strong> 이라는 파일기반 자료구조를 사용한다.<br>HFile은 MapFile과 유사하지만 index를 다른 파일로 분리하지않고 같은파일에서 관리하도록 하며 여러 metadata를 담을 수 있다.<br>HFile 내부에는 data block이 여러개가 존재한다. 여러개의 연속된 data block들이 존재하고 index도 같이 존재한다. 이 data block에는 실제 key-value 데이터를 담고있다. 각 data block의 첫번째 key가 index에 기록된다. data block은 기본설정으로 64KB의 크기를 가진다.<br>각 HFile의 data block에는 HBase cell 들이 KeyValue 형태로 연속해서 저장되어 있다.<br>아래는 HFile version 1의 구조이다.  </p>
<p align="center">
    <img alt="HFile version 1" style="max-width: 700px;" src="/images/hadoop/hfile-v1.png"/>
</p>

<p>Block index에는 각 entry마다 block의 size, key 정보 등이 들어있다. 
HFile에는 위와같이 metadata를 담는 block인 Meta Block과 File Info 가 존재한다. version 1에서는 이 Meta Block을 Bloom Filter 정보를 담는데에 활용하였다. data scan시 해당 data가 이 HFile에 있는지 bloom filter를 활용하면 빠르게 판단할 수 있는데 bloom filter는 false positive가 발생한다. 그래서 HFile이 너무 오래되었는지 확인하기위한 Max SequenceId, Timerage 등을 File Info에 저장해 false positive를 한번 더 필터링한다.  </p>
<h6 id="HFile-version-2"><a href="#HFile-version-2" class="headerlink" title="HFile version 2"></a>HFile version 2</h6><p>HBase 0.92 버전에서는 많은 데이터가 저장될 때 성능개선을 위해 HFile 형식이 조금 변경되었다.<br>위의 HFile version 1에서는 데이터를 읽기 위해서는 해당 HFile의 전체 데이터 정보를 담고있는 단일 index와 bloom filter를 메모리에 모두 올려놓아야 했다. 이를 개선하기 위해 HFile version 2 에서는 bloom filter를 block 별로 두고, multi-level index를 사용하도록 개선했다.  </p>
<p align="center">
    <img alt="HFile version 2" style="max-width: 700px;" src="/images/hadoop/hfile-v2.png"/>
</p>

<p>HFile version 2 에서는 bloom filter block과 index block을 data block과 나란히 배치한다.<br>bloom filter block과 index block 모두 random read을 최적화하기위한 용도로 사용된다. index block은 index data로 빠르게 검색할 수 있도록 하며, bloom filter block은 해당 data가 있는지 없는지를 빠르게 필터링하는데에 사용된다.  </p>
<p>Index block 에는 3가지가 있다. Root Index block, Intermediate Index block, Leaf Index block 이다.<br>Root Index block은 HFile을 읽을때 바로 memory로 올린다. Root Index는 각 entry가 Intermediate Index block을 가리킨다. 그리고 Intermediate Index의 각 entry는 Leaf index block을 가리킨다. 마지막으로 Leaf index block은 실제 data block 을 가리킨다. 이는 b+tree와 매우 유사한 구조이다.  </p>
<p align="center">
    <img alt="HBase multi-level index" style="max-width: 700px;" src="/images/hadoop/hbase-multi-level-index.png"/>
</p>

<p>각 index entry에서의 key를 구성하는 것은 크게 두가지 방식이 있다. <strong>Rowkey-based index</strong> 와 <strong>Column-based index</strong> 이다.<br>Rowkey-based index 는 HBase 의 built-in 인덱스 방식으로 rowkey 를 기반으로 특정 row를 빠르게 찾도록 도와준다. rowkey-based index 는 key로 rowkey를 포함한다.  </p>
<p>Column-based index 는 HBase 의 secondary index 구현에 사용된다. 이는 특정 column qualifier 값의 질의를 빠르게 매칭하는데 사용한다. column-based index 는 index table 이라고 불리는 HBase 의 또다른 테이블에 저장된다. index table 구조는 HBase 의 테이블과 유사하며 동일한 rowkey 와 column 을 사용한다. 하지만 value 는 기존의 테이블의 부분만 가지고있다.<br>따라서 특정 쿼리에서 column-based index 를 사용해야한다고 판단할때는 index table 을 보고 일치하는 row를 먼저 골라낸다. 그 다음 해당 row를 실제 main table 에서 찾는다.<br>따라서 특정 column qualifier value를 조회할때에는 column-based index 가 조회가 필요한 row 만 필터링해줄 수 있으므로 성능향상을 가져올 수 있다.  </p>
<h4 id="HFile-block"><a href="#HFile-block" class="headerlink" title="HFile block"></a>HFile block</h4><p>HBase 에서 조회를 할때 조회해야하는 row가 포함되어있는 HFile block을 찾는다. 이는 index 에서 rowkey로 검색하여 찾을 수 있다.<br>그리고 그 HFile block을 rowkey를 활용해 찾으면 이 block 전체를 메모리에 올린다. 이들은 정렬되어있는 key-value 쌍이므로 binary search 로 원하는 row 조회 및 특정 column qualifier 조회를 수행할 수 있다.  </p>
<p>Data block에도 header를 포함한다.  </p>
<p align="center">
    <img alt="HFile data header" style="max-width: 500px;" src="/images/hadoop/hfile-block-header.png"/>
</p>

<p>header에는 Block Type을 포함하여 해당 block이 data block인지 Index 인지 다른 내용인지를 구별하도록 한다. 또한 이전 block의 offset도 저장하여 빠른 backward seek을 가능하도록 한다.   </p>
<p>HBase는 이처럼 데이터를 HFile이라는 큰 파일에 저장한다. 보통 HFile은 몇백 MB 부터 시작해 GB 단위로 커져간다.  </p>
<br/>

<h2 id="HBase-read"><a href="#HBase-read" class="headerlink" title="HBase read"></a>HBase read</h2><p>HBase의 read는 쉽다. 먼저 <code>Get</code> command instance를 통해 읽고싶은 cell을 지정하고 table에 보내면 된다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Get</span> <span class="hljs-variable">g</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Get</span>(Bytes.toBytes(<span class="hljs-string">&quot;TK-one&quot;</span>));<br><span class="hljs-type">Result</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> usersTable.get(g);<br></code></pre></td></tr></table></figure>
<p>table은 <code>Result</code> 객체를 반환하는데 이 객체는 해당 row의 모든 column family의 모든 column 들을 포함한다. 다만 이는 우리가 필요한 데이터보다 더 많을수 있으므로 구체적으로 얻고싶은 column만 명시를 할수도 있다.   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Get</span> <span class="hljs-variable">g</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Get</span>(Bytes.toBytes(<span class="hljs-string">&quot;Tk-one&quot;</span>);<br>g.addColumn(Bytes.toBytes(<span class="hljs-string">&quot;info&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;name&quot;</span>));<br><span class="hljs-type">Result</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> usersTable.get(g);<br></code></pre></td></tr></table></figure>
<p>위에서는 <code>addColumn()</code> 메서드를 통해 원하는 column을 명시했지만 <code>addFamily()</code> 메서드를 활용하면 해당 column family의 전체 column을 가져올 수도 있다.  </p>
<p>HBase는 대부분의 읽기를 millisecond 단위로 제공한다. 보통의 일반적인 방법과 같이 HBase도 빠른 data access를 위해 data를 정렬된 상태로 유지하고 memory에 많이 올려놓는다. 그리고 위에서 설명하였듯이 write는 MemStore에 저장되지만 MemStore는 HFile로 flush되므로 read command를 처리하기 위해서는 HFile과 MemStore에서 적절하게 데이터를 잘 찾아야한다.  </p>
<p>HBase는 <strong>BlockCache</strong>라는 LRU Cache를 내부적으로 사용한다. 이 BlockCache는 JVM heap에 MemStore옆에 위치한다. BlockCache는 HFile에서 자주 접근되는 data들을 캐싱해서 in-memory hit를 하고 disk read를 줄이기 위한 목적이다. 각 column family마다 BlockCache를 가지고있다.<br>HBase를 최적의 성능을 내도록 하기위해서는 BlockCache를 이해하는게 중요하다.  </p>
<br/>

<h4 id="BlockCache"><a href="#BlockCache" class="headerlink" title="BlockCache"></a>BlockCache</h4><p>BlockCache의 Block은 HBase에서 disk에서 한번에 읽는 데이터 단위이다. 위의 HFile 에서의 data block이 이것이다.<br>HBase가 데이터를 읽기위해 HFile을 뒤져야할때는 HFile의 index 를 보고 binary search를 통해 key를 포함하고 있는 block의 위치를 알아낸 뒤 그 block(64KB)를 HDFS로 부터 읽어낸다. block size는 column family 별로 다르게 설정될 수 있으며 기본값은 64KB이다.<br>만약 Application이 HBase에서 random lookup이 많다면 block size를 작게하는게 도움이 될 수 있다. 반면 block size가 작아지면 block의 개수가 많아지므로 index는 조금 더 커질 것이다. sequential lookup이 많다면 block size를 반대로 크게 하는게 도움이 된다.  </p>
<p>BlockCache는 기본적으로 enable 된다. 즉 모든 read operation은 그에 연관된 block을 BlockCache에 올릴것이다. BlockCache는 내부적으로 block들의 종류에 따라 evict 정책을 다르게 가져간다.<br>예를들어 <code>hbase:meta</code> table 내용은 최대한 BlockCache에서 evict 되지 않도록한다.<br>HFile의 index 들도 BlockCache에 올라가는데 자주 사용되지 않는 index들은 evict된다. HFile index들은 multi-layered index로 HBase에서 data를 찾을때 빠르게 찾을 수 있도록 도와준다. 이 말고도 BloomFilter도 활성화되어있다면 BlockCache에 올린다.<br>기본적인 key-value data 들도 당연히 BlockCache에 올라간다.<br>같은 데이터를 여러번 접근하는 패턴은 BlockCache의 이득을 최대로 볼 수 있다.  </p>
<p>HBase에서 row를 읽을때에는 먼저 MemStore를 확인한다. 그 다음 BlockCache를 확인하고 해당 row가 BlockCache에 올라와있는지 확인한다. 최근에 row가 접근된 적이 있다면 BlockCache에 존재할 확률이 높다. 만약 BlockCache에도 찾지못한다면 그때 관련된 HFile들을 확인한다. 이때에는 disk read가 발생한다. 완전한 row를 찾기위해서는 모든 HFile을 뒤져야한다.  </p>
<br/>

<h2 id="HBase-delete"><a href="#HBase-delete" class="headerlink" title="HBase delete"></a>HBase delete</h2><p>Delete는 HBase의 데이터를 저장하는 방식과 비슷하게 작동한다. 먼저 Delete를 하려면 <code>Delete</code> command의 인스턴스를 생성해야한다.<br>다음은 rowkey를 명시하여 해당 row를 삭제하는 코드이다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Delete</span> <span class="hljs-variable">d</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Delete</span>(Bytes.toBytes(<span class="hljs-string">&quot;TK-one&quot;</span>));<br>userTables.delete(d);<br></code></pre></td></tr></table></figure>
<p>row 자체를 전부 삭제하는게 아닌 특정 coordinate를 명시해서 해당 cell만 삭제할 수도 있다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Delete</span> <span class="hljs-variable">d</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Delete</span>(Bytes.toBytes(<span class="hljs-string">&quot;TK-one&quot;</span>));<br>d.deleteColumns(Bytes.toBytes(<span class="hljs-string">&quot;info&quot;</span>), Bytes.toBytes(<span class="hljs-string">&quot;name&quot;</span>));<br>userTables.delete(d);<br></code></pre></td></tr></table></figure>
<p>실제 삭제는 어떻게 진행될까?<br>실제로 <code>Delete</code> command는 해당 값을 바로 삭제하지 않는다. 대신에 해당 record가 삭제되었다는 마킹만 한다.  이는 HFile을 생각해보면 당연한 설계이다. HFile은 immutable하다. 그러므로 애초에 record를 수정하거나 삭제할 수가 없다. 그러므로 해당 record가 삭제되었다는 <strong>새로운 record를 write</strong>한다. 이를 <strong>tombstone</strong> 이라고 한다. 그래서 보통 HBase 에서 삭제한다고 하면 tombstone marking을 했다고 표현한다.<br>이 tombstone mark는 <code>Get</code>이나 <code>Scan</code>을 할때 해당 record가 결과에 포함되지 않도록 보장한다. 실제 삭제가 되었어야 하는 original 데이터는 계속해서 HFile에 남아있을 수 밖에 없는데, 이런 데이터들은 밑에서 볼 <strong>major compaction</strong> 단계에서 제거된다.  </p>
<br/>

<h2 id="HBase-Compaction"><a href="#HBase-Compaction" class="headerlink" title="HBase Compaction"></a>HBase Compaction</h2><p>Memstore가 어느정도 크기에 도달하거나 Region 서버가 Memstore에 너무 많은 메모리를 쓰고있다고 판단되면 Memstore는 flush를 하여 새로운 HFile을 만들어낸다고 했다.<br>매 flush마다 새로운 HFile이 생성되므로, 우리는 <code>Get</code>과 <code>Scan</code>을 수행할때 key를 찾기위해 해당 요청과 관련있는 모든 HFile을 다 뒤져봐야하므로 이는 성능이 좋지않다. 즉 HFile의 개수를 제한하는 것이 성능에 매우 중요한 부분을 차지한다. 이를 극복하기위해 HBase는 HFile의 개수가 특정개수를 넘어갈때 <strong>Compaction</strong>을 진행하여 여러개의 HFile을 하나의 큰 HFile로 병합한다.  </p>
<p>HBase의 compaction에는 2가지 종류가 있다. <strong>Minor Compaction</strong>과 <strong>Major Compaction</strong>이다.  </p>
<br/>

<h4 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h4><p>minor compaction은 간단하다. 작은 HFile 여러개를 하나의 큰 HFile로 합친다. minor compaction 과정은 HBase에 성능저하를 최소한으로 있도록 설계되었기 때문에 minor compaction 대상이되는 HFile 개수는 상한선이 있다. 이 값은 설정값으로 조정이 가능하다.<br>minor compaction은 작은 HFile 들로부터 record를 읽어 이들을 정렬하고 큰 HFile에 새로 write한다. 과정은 다음 그림과 같다.  </p>
<p align="center">
    <img alt="minor compaction in HBase" style="max-width: 600px;" src="/images/hadoop/major-compaction.png"/>
</p>

<br/>

<h4 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h4><p>major compaction은 column family의 모든 HFile를 대상으로 수행되는 compaction이다. major compaction이 완료되면 해당 column family의 모든 HFile들은 하나의 HFile로 병합된다. 이 major compaction은 비용이 비싸므로 자주 일어나지 않는다. 다만 minor compaction은 빈번하게 일어난다.<br>major compaction 단계에서는 tombstone marker로 표시해둔 record를 완전히 삭제한다. 또한 tombstone marker record 자체도 같이 삭제한다.  </p>
<p>왜 minor compaction은 이와같은 deleted mark record를 삭제하지 못할까?<br>실제로 삭제대상의 record가 있는 HFile과 tombstone marker record가 있는 HFile은 다를 수 있고 삭제대상의 record가 어느 HFile에 있는지 모르기 때문이다. minor compaction은 작은 몇개의 HFile을 대상으로만 진행된다. 그러므로 major compaction에서 이를 담당한다.  </p>
<h4 id="HBase-data-locality"><a href="#HBase-data-locality" class="headerlink" title="HBase data locality"></a>HBase data locality</h4><p>HBase는 HDFS로부터 HFile을 읽을때 어느 node에서 읽을까?<br>이를 위해서는 먼저 HBase와 HDFS가 같은 cluster에 있는지 확인해야한다. 만약 같은 cluster에 없다면 HFile은 항상 HBase의 Region server와 다른 노드에 있으므로 network 비용이 발생한다.<br>만약 같은 cluster에 존재한다면 Region Server가 HDFS에 HFile을 쓸 때 HDFS는 가능하면 그 파일을 쓰는 datanode에 replica가 저장될 수 있도록 해준다. 따라서 Region Server에서 HFile 접근시 local disk에 접근하므로 data locality를 보장할 수 있다.<br>만약 Region Server가 문제가 생겨 새로 서버가 시작되었다고 하더라도 처음에는 다른 HFile을 읽기위해 다른 HDFS datanode로 부터 파일을 읽어오겠지만, 충분한 시간이 지난다면 major compaction이 발생하고 결국 HFile을 새로 다시 쓰기때문에 이 부분에서 다시한번 data locality를 보장할 수 있다.  </p>
<br/>

<h2 id="HBase-분산모드"><a href="#HBase-분산모드" class="headerlink" title="HBase 분산모드"></a>HBase 분산모드</h2><p>HBase의 테이블은 row와 column으로 구성되어 있고 수십억개의 row와 수백만 개의 column으로 확장이 가능하다. 각 테이블은 petabyte 단위까지도 증가할 수 있다. 다만 단일머신에서는 이를 서비스하기 힘들다. 어떻게 이를 가능하게 할까?  </p>
<p>HBase는 table을 작은 단위로 분할시키고 이를 여러 서버에 나누어 서비스한다. 이 작은 단위를 <strong>Region</strong> 이라고 부른다. 이 Region을 서비스하는 서버를 <strong>RegionServer</strong> 라고 한다.<br>일반적으로는 RegionServer 들은 HDFS datanode와 같은 물리적인 서버에 위치해 있다. 꼭 같은 물리서버에 위치해야할 필요는 없지만 locality를 얻기위해 그리고 성능최적화를 위해서는 같은 물리적 서버에 위치하도록 하는게 좋다. RegionServer 들은 HDFS의 입장에서는 HDFS를 사용하는 클라이언트중 하나이다.<br>HMaster라 불리는 process가 region을 할당하고 분배하는 역할을 수행하고 각 RegionServer는 일반적으로는 여러개의 Region을 서비스한다.<br>Region은 table을 rowkey를 기준으로 적절하게 범위를 나누어 할당된다. 다음 그림으로 Region의 분리를 볼 수 있다.  </p>
<p align="center">
    <img alt="table to region" style="max-width: 700px;" src="/images/hadoop/hbase-region-example.png"/>
</p>

<p>Region이 너무 커지거나 Region이 나누어져야 하는 특정조건을 만족하면 RegionServer는 Region을 다시 작은 크기로 쪼갠다.  </p>
<p>client 가 특정 row에 접근하고자 할때는 어느 Region에 있고 이를 어떤 RegionServer가 호스팅하고 있는지 어떻게 알 수 있을까?<br>이 정보는 <strong>.META.</strong> 라는 HBase 내의 table이 도움을 준다. 실제 table 이름은 <code>hbase:meta</code> 이며 HBase의 모든 region 정보를 가지고 있다. 그리고 zookeeper가 <code>hbase:meta</code> table의 위치를 저장한다. .META. 테이블은 1개의 region으로만 사용하고 있다.  </p>
<p>따라서 client는 특정 row에 접근할때 zookeeper로부터 <code>hbase:meta</code> region을 서비스하는 RegionServer를 알아내고, 이 .META. table 정보를 들고있는 RegionServer에 해당 rowkey를 어떤 region과 RegionServer 에서 제공하고 있는지 질의한다.<br>그에 대한 RegionServer 정보를 받으면 그 RegionServer로 해당 row의 읽기나 쓰기작업을 진행한다.  </p>
<br/>

<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.quora.com/Why-does-HBase-keep-WAL-on-HDFS-instead-of-local-disks">https://www.quora.com/Why-does-HBase-keep-WAL-on-HDFS-instead-of-local-disks</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.cloudera.com/apache-hbase-i-o-hfile/">https://blog.cloudera.com/apache-hbase-i-o-hfile/</a></li>
<li><a target="_blank" rel="noopener" href="https://nag-9-s.gitbook.io/hbase/hbase-architecture/region-servers/hfile">https://nag-9-s.gitbook.io/hbase/hbase-architecture/region-servers/hfile</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-03-23T13:42:24.000Z" title="23/03/2022, 22:42:24">2022-03-23</time>&nbsp;게시 됨</span><span class="level-item"><a class="link-muted" href="/categories/Hadoop/">Hadoop</a></span><span class="level-item">30분안에 읽기 (약 4501 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/23/hadoop-hdfs/">Hadoop HDFS란?</a></h1><div class="content"><p>현 회사에서 Hadoop을 적극적으로 사용하고 있고 저장소로 HBase를 사용하며 MR(MapReduce)을 다루는 경우가 많기 때문에 Hadoop 관련 내용을 정리하면 좋겠다고 생각했다.<br>이 글을 읽기 전에 <a href="/2020/09/05/file-system-hard-disk/">파일시스템 1편 - 하드디스크</a> 를 먼저 읽으면 도움이 될 수 있습니다.  </p>
<p>먼저 Hadoop distributed file system을 알아보자.  </p>
<p align="center">
    <img style="max-width: 700px;" src="/images/hadoop/hadoop.png"/>
</p>

<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>HDFS는 Hadoop Distributed File System 의 약어다.<br>HDFS는 하둡의 대표적인 분산파일시스템이다. 그렇다고 하둡에서 꼭 HDFS를 사용해야하는 것은 아니다. 하둡은 범용 파일시스템을 추구한다. 하둡은 파일시스템의 추상화개념을 가지고있고 HDFS는 그 구현체 중 하나일 뿐이다.<br>데이터가 단일 디스크의 저장용량을 초과하면 이 데이터들을 쪼개서 여러개의 머신에 저장해야한다. 이렇게 여러개의 머신으로 파일을 저장하고 서로 네트워크로 묶으면 여러머신의 스토리지를 관리할 수 있는데 이를 분산파일시스템이라고 한다.  </p>
<p>HDFS는 여러개의 머신으로 구성된 클러스터에서 실행되고 대용량 파일을 다룰 수 있도록 설계된 파일시스템이다.<br>HDFS는 petabyte단위의 파일을 다룰 수 있고 하드웨어는 항상 장애가 날 수 있는데 노드장애가 발생하더라도 대형 클러스터에서 문제없이 실행되도록 설계되었다.  </p>
<p>HDFS는 기본적으로 빠른 응답시간을 요구하는 애플리케이션에는 맞지않다. 설계자체가 높은 데이터 처리량을 제공을 목표로 하기 때문이다. 빠른 응답시간을 원하면 HBase가 선택지가 될 수 있겠다.<br>그리고 HDFS는 파일을 생성하거나 파일 끝에 append하는 것은 가능하지만 파일 중간에 내용을 update하는 것은 불가능하다. 한번의 쓰기작업 그리고 여러번 읽는 방식이 가장 효율적인 방식이도록 설계되었기 때문에 데이터를 수정하려면 현재 데이터를 삭제후 수정한 데이터를 새로 생성해야 한다.  </p>
<br/>

<h2 id="HDFS-Block"><a href="#HDFS-Block" class="headerlink" title="HDFS Block"></a>HDFS Block</h2><p>여기서 말하는 block은 흔히 파일시스템에서 말하는 block을 말한다.<br>보통 우리가 아는 단일디스크에서의 파일시스템에서 사용하는 block는 4KB이고, 디스크 자체는 기본적으로 512KB의 sector size를 가진다.<br>이와같이 HDFS도 block 개념이 있는데 HDFS block은 size가 굉장히 크다.<br>HDFS block size는 기본적으로 128MB이며 보통은 이것보다는 큰 block size를 사용한다. 
HDFS block이 큰 이유는 기본적으로  탐색비용(disk에서의 seek time + rotational delay)을 줄이기 위함이다. (SSD에서도 sequential read가 random read 보다 빠르다)<br>Disk seek 비용은 상당히 비싸다. Hadoop은 전체 dataset을 탐색하도록 설계되었기 때문에 큰 block size로 sequential read를 통해 성능을 크게 개선할 수 있다.<br>예를들어 position time(seek time + rotational delay)가 10ms 이고, disk 전송률이 100MB&#x2F;s 일때 position time을 전송시간의 1%로 만들고 싶다면 block size를 100MB로 잡으면된다.(position time 10ms + 100MB 전송에 1초가 걸리므로)  </p>
<p>또 만약에 block size가 작으면 파일에 대한 block의 개수자체도 많아질텐데 뒤에 보면 알겠지만 HDFS는 파일시스템 metadata를 메모리에서 관리한다. 그러면 모든 block에 대해 metadata를 들고 있어야 하는데 block 개수자체가 많아지므로 metadata가 너무 커지는 문제가 있다. 결국 block이 너무 많으면 오버헤드가 발생하고 네트워크 트래픽이 증가하는 문제가 발생할 수 있다.<br>HDFS에서의 파일은 우리가 단일디스크 파일시스템에서 파일을 저장할 때처럼 block size별로 chunk되어 저장된다.<br>다만 HDFS는 데이터가 block size보다 작을경우, 해당 block(128MB)을 모두 차지하지는 않는다(기본적인 단일디스크 파일시스템에서는 데이터가 4KB 보다 작아도 4KB block을 모두 차지한다). 그러므로 파일크기가 block size보다 작다고 공간이 버려지지는 않는다.</p>
<p>HDFS에도 block 개념이 있기때문에 여러가지 이점이 있는데 먼저 단일디스크에 있는 파일시스템에 다 담지 못하는 크기의 파일도 여러 block으로 나누어 여러 디스크에 저장할 수 있다. 그리고 block 단위의 추상화가 들어가면 스토리지의 subsystem을 단순화할 수 있고 metadata 관리가 편하다. 또 block은 fault tolerance와 availability를 제공하기 위한 replication을 구현하는데에 적합하다. block 마다 replicaion factor 개수만큼 여러머신에 중복저장하고 특정 노드에서 block을 읽을 수 없다면 다른 노드를 사용하게 할 수있다.</p>
<br/>

<h2 id="Namenode-And-Datanode"><a href="#Namenode-And-Datanode" class="headerlink" title="Namenode And Datanode"></a>Namenode And Datanode</h2><p>HDFS cluster는 master인 네임노드와 worker인 데이터노드로 구성되어 있다.<br>네임노드는 파일시스템 트리, 그리고 그 트리에 포함된 모든 파일, 디렉터리에 대한 metadata를 유지한다. 파일시스템에서 inode를 네임노드에서 관리하고 있다고 이해하면 좋겠다. 그리고 이 내용은 namespace image와 edit log라는 두 종류의 파일로 local disk에 영구히 저장된다.<br>네임노드는 모든 HDFS block이 어느 데이터노드에 있는지 모두 알고있다. 하지만 이 정보는 local disk에 영속 저장하지는 않고 시스템 시작시 데이터노드로 부터 받아서 재구성한다. 따라서 네임노드를 다른 것으로 교체할 때 전체 데이터노드에서 충분한 block report를 받아 안전모드를 벗어날때까지 요청을 처리할 수 없는데 이 시간이 30분이상 걸리기도 한다.  </p>
<p>사용자가 직접 네임노드, 데이터노드와 통신해야 하는것은 아니고 이 모든 것을 HDFS client가 대신해서 이들에게 접근한다.<br>데이터노드는 HDFS client나 네임노드의 요청이 있을때 block을 저장하고 탐색하며, 주기적으로 저장하고 있는 block list들을 네임노드에 보고한다.<br>또 네임노드는 모든 파일과 각 block의 참조정보를 다 메모리에 들고있다. 그래서 대형 cluster에서는 메모리가 걸림돌이 되는데 이부분은 HBase Federation을 적용하여 해결할 수 있다. 이는 네임노드를 여러개두고 각 네임노드가 특정 namespace를 담당하도록 하는 것이다. 예를들어 어떤 네임노드는 <code>/user</code>을 관리하고 어떤 네임노드는 <code>/bar</code>를 관리할 수 있다. 그러면 특정 네임노드가 장애가 나도 다른 namespace의 가용성에는 영향을 주지 않는 장점도 있다.<br>HDFS는 네임노드가 정말 중요한데 네임노드가 장애면 시스템의 어떤 파일도 찾을 수 없다. 모든 block 정보를 이용해 네임노드가 파일을 재구성하기 때문이다. 그래서 네임노드의 장애극복은 필수적이며, Hadoop은 이를위해 2.x 부터 HDFS HA를 지원한다.    </p>
<p>HA는 보조 네임노드를 운영한다. 네임노드를 Active-StandBy 구조로 한 쌍으로 구성하여 Active 네임노드에 장애가 발생할 경우 StandBy 네임노드가 이를 이어받는 방식이다.</p>
<br/>

<h2 id="File-read"><a href="#File-read" class="headerlink" title="File read"></a>File read</h2><p>클라이언트가 HDFS의 파일을 읽을때 내부적으로 어떤 일이 일어나는지 살펴보자.  </p>
<p align="center">
    <img alt="HDFS File read" src="/images/hadoop/hdfs-file-read.png"/>
</p>
  
<p>먼저 클라이언트는 hadoop에서 제공하는 <code>FileSystem</code> 객체의 <code>open()</code>을 호출하여 원하는 파일을 열어야한다. 그러면 해당 파일의 첫번째 block이 어디있는지 파악하기 위해 RPC로 네임노드를 호출한다. 그러면 네임노드는 block 별로 해당 block의 복제본을 가진 데이터노드의 주소를 반환한다. 이때 데이터노드의 순서는 cluster의 network topology에 따라 클라이언트에 가장 가까운순으로 정렬되어 반환된다. 예를들어 클라이언트 자체가 데이터노드고 해당 block의 복제본을 본인이 가지고 있으면 첫번째 데이터노드는 로컬이 될 것이다.  </p>
<p>block 위치정보를 반환받으면 이 정보를 기반으로 데이터를 읽을 수 있도록 <code>FSDataInputStream</code>을 반환한다. 이는 스트림으로 클라이언트는 read 메서드를 호출하면된다. 그때 내부적으로 첫번째 데이터노드와 연결해 데이터를 전송받는다. 만약 block의 끝에 도달했으면 다음 block의 데이터노드와 연결해 데이터를 전송받는다. 이 과정은 내부적으로 일어나며 클라이언트는 스트림을 읽는것처럼 보인다.  </p>
<p>만약 데이터노드와의 통신에 문제가 생기면 해당 block을 저장하고 있는 다음 데이터노드와 연결을 시도하고, 문제가 생긴 데이터노드는 네임노드에 report한다.<br>전반적인 읽기는 클라이언트가 데이터노드에 직접 접근하여 데이터를 읽어오고, 네임노드가 각 block의 데이터노드를 적절하게 알려준다. 이런 과정을 통해 File 읽기에 대한 트래픽은 모든 데이터노드에 고르게 분산된다. 네임노드는 모든 클라이언트의 요청을 처리해야하지만 메타데이터를 메모리에 저장하여 memory read로 끝나기때문에 많은 클라이언트의 요청을 동시에 처리할 수 있다.  </p>
<br/>

<h2 id="File-write"><a href="#File-write" class="headerlink" title="File write"></a>File write</h2><p>클라이언트가 HDFS의 파일을 쓰게될때 어떤 일이 일어나는지 살펴보자.  </p>
<p align="center">
    <img alt="HDFS File write" src="/images/hadoop/hdfs-file-write.png"/>
</p>
  
<p>클라이언트는 <code>DistributedFileSystem</code>의 <code>create()</code> 메서드를 호출하여 파일을 생성한다. 그러면 네임노드에 RPC를 보내는데 이때는 파일생성권한이 적절하게 있는지 동일파일이 존재하는지 등 검사를 진행한다. 검사가 통과되면 새로운 파일의 레코드를 만들어 저장하고 반환한다. 이때 block 정보는 반환하지 않는다.<br>클라이언트는 file read와 마찬가지로 <code>FSDataOutputStream</code>을 반환받고 이를 스트림으로 write할 수 있다. 다만 쓸때는 read 과정과 조금 다르다.  </p>
<p>클라이언트가 파일에 데이터를 쓸때에는 각 데이터를 패킷으로 나누어 분리하고 클라이언트의 내부 queue인 data queue라고 불리는 queue에 해당 패킷들을 쌓는다. 그러면 <code>DataStreamer</code>가 이 패킷들을 처리한다. 먼저 block을 어느 데이터노드에 써야하는지 모르므로, 네임노드로부터 복제본을 저장할 데이터노드 목록을 요청하고 반환받는다.<br>다만 이 데이터노드들은 pipeline을 형성하는데 replication factor가 3이라면 세개의 노드가 pipeline에 속한다.<br><code>DataStreamer</code>는 첫번째 데이터노드에 먼저 패킷들을 전송한다. 첫번째 데이터노드는 이를 저장하고 나서 이를 다음 pipeline의 데이터노드로 보낸다. 이어서 두번째 데이터노드는 다시 패킷을 저장하고 다음 pipeline의 데이터노드로 저장한다. 그림을 보면 이와같은 내용을 설명하고 있다.  </p>
<p>클라이언트는 내부 패킷을 저장하는 ack queue를 들고있어 각 데이터노드로 부터 ack 응답을 전부 받으면 해당 패킷이 queue에서 삭제된다.<br>만약 데이터노드의 쓰기에 문제가 있다면 ack를 받지못한다. 그러면 장애복구작업이 시작되는데 ack queue에 있는 패킷들이 다시 data queue에 들어가서 재시도된다.  </p>
<p>즉 file write는 비동기적으로 pipeline을 통해 데이터노드에 써주게되는데 <code>dfs.namenode.replication.min</code>에 설정된 개수의 데이터노드에만 block 저장이 성공하면 write은 성공한 것으로 반환된다. 기본값은 1 이다. 그리고 <code>dfs.replication</code> 값인 replication factor에 도달할때까지 클러스터에 걸쳐 복제가 비동기적으로 수행된다. replication factor의 기본값은 3이다.  </p>
<p>클라이언트가 file write을 다했을때는 <code>close()</code> 메서드를 호출한다. 그러면 클라이언트는 데이터노드 pipeline으로 남아있는 모든 패킷을 flush하고 ack를 기다린다. 그 이후에는 네임노드에 file write이 완료되었음을 알린다. <code>dfs.namenode.replication.min</code> 만큼의 block이 복제가 완료되었으면 성공을 반환한다.  </p>
<br/>

<h4 id="복제본-배치"><a href="#복제본-배치" class="headerlink" title="복제본 배치"></a>복제본 배치</h4><p>네임노드는 복제본을 저장할 데이터노드를 어떻게 선택할까?<br>노드간의 쓰기 대역폭을 줄이기위해 단일노드에 모두 복제본을 배치하면 복제의 의미가 없다. 해당 노드가 장애시 data loss가 일어난다.  </p>
<p>하둡에서는 첫번째 복제본은 클라이언트와 같은 노드에 배치한다. 그런데 클라이언트가 cluster 내부의 노드가 아니라면 무작위로 노드를 선택한다. 이 과정에서 노드들의 파일개수나 해당 노드의 자원상황을 고려한다.<br>두번째 복제본은 첫번째 복제본을 저장한 노드와 <strong>다른 랙</strong>에서 노드를 무작위로 선택한다. 세번째 복제본은 두번째 복제본이 저장되는 랙과 동일한 랙에서 다른 노드를 선택한다. 그 이상의 replication factor를 가졌다면 다음 노드들은 무작위로 선택한다.  </p>
<p>하둡은 block을 두개의 랙에 저장함으로서 신뢰성을 가지고, 쓰기 대역폭은 하나 혹은 두개의 네트워크 스위치만 통하도록 설계되었다. 읽기 성능을 위해서도 두개의 랙중 가까운 것을 선택하도록 한다. 그리고 전반적인 cluster의 block 분산의 균형을 적절하게 맞춘다.  </p>
<p align="center">
    <img alt="HDFS block copy 배치" style="max-width: 400px;" src="/images/hadoop/hdfs-block-copy.png"/>
</p>

<br/>

<h2 id="일관성-모델"><a href="#일관성-모델" class="headerlink" title="일관성 모델"></a>일관성 모델</h2><p>일관성 모델은 coherence model 로 부른다. 이는 파일에 대한 read, write에 대해 visibility 가 어떻게 되는지 설명한다.<br>HDFS에서 파일을 생성하면 HDFS namespace에서 파일의 존재를 확인할 수 있다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Path</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;p&quot;</span>);<br>fs.create(p);<br>assertThat(fs.exists(p), is(<span class="hljs-literal">true</span>));<br></code></pre></td></tr></table></figure>
<p>하지만 파일을 write 할 때, 스트림을 flush 했다고 해서 해당 파일의 내용일 읽을 수 있음을 보장하지는 않는다.<br>다음 예제처럼 stream을 flush하고 읽었을때 파일의 내용이 비어있을 수 있다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Path</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;p&quot;</span>);<br><span class="hljs-type">OutputStream</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> fs.create(p);<br>out.write(<span class="hljs-string">&quot;content&quot;</span>.getBytes(<span class="hljs-string">&quot;UTF-8&quot;</span>));<br>out.flush();<br>assertThat(fs.getFileStatus(p).getLen(), is(<span class="hljs-number">0L</span>));<br></code></pre></td></tr></table></figure>

<p>일단 file의 데이터가 한 개의 block 넘게 기록이 되면, 그 file의 첫번째 block은 reader들이 볼 수 있다.<br>다만, 현재 쓰여지고 있는 block은 다른 reader 들에게 보이지 않을 수 있다.  </p>
<p>HDFS는 모든 buffer들이 데이터노드들에 강제로 flush 할 수 있는 <code>hflush()</code> 라는 메서드를 제공한다.<br><code>hflush()</code>가 성공하면, HDFS는 write pipeline에 속한 모든 데이터노드들에 file write에 대한 요청이 도달했음을 보장해준다. 그러므로 모든 다른 reader들이 이를 읽을 수 있다.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Path</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;p&quot;</span>);<br><span class="hljs-type">OutputStream</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> fs.create(p);<br>out.write(<span class="hljs-string">&quot;content&quot;</span>.getBytes(<span class="hljs-string">&quot;UTF-8&quot;</span>));<br>out.hflush();<br>assertThat(fs.getFileStatus(p).getLen(), is((<span class="hljs-type">long</span>) <span class="hljs-string">&quot;content&quot;</span>.length()));<br></code></pre></td></tr></table></figure>

<p>한가지 주의해야 할 점은 <code>hflush()</code>는 데이터노드가 해당 파일을 disk에 썼음을 보장하지 않는다. 오직 데이터노드의 메모리에 썼음을 보장한다. 따라서 <code>hflush()</code>를 호출했음에도 data center 장애가 일어나면 데이터 유실이 일어날 수 있다.<br>데이터노드에서의 disk write도 보장하고 싶다면 <code>hsync()</code>를 호출해야 한다.  </p>
<p><code>hsync()</code>는 POSIX의 <code>fsync()</code>와 같다. 파일시스템 편에서의 buffer cache를 flush 하기 위한 <code>fsync()</code>를 기억하라.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Path</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;p&quot;</span>);<br><span class="hljs-type">OutputStream</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> fs.create(p);<br>out.write(<span class="hljs-string">&quot;content&quot;</span>.getBytes(<span class="hljs-string">&quot;UTF-8&quot;</span>));<br>out.flush();<br>out.getFD().sync(); <span class="hljs-comment">// disk에 sync를 보장한다.</span><br>assertThat(fs.getFileStatus(p).getLen(), is((<span class="hljs-type">long</span>) <span class="hljs-string">&quot;content&quot;</span>.length()));<br></code></pre></td></tr></table></figure>

<p>HDFS에서의 <code>close()</code> 메서드는 내부적으로 <code>hflush()</code>를 호출한다.  </p>
<p>이런 HDFS의 일관성 모델을 보고 애플리케이션의 디자인을 어떻게 해야할지 결정해야한다.<br><code>hflush()</code>나 <code>hsync()</code> 없이는 block의 저장을 보장할 수 없다. 하지만 이에도 tradeoff가 있다. <code>hflush()</code>는 비싼작업은 아니지만 그래도 오버헤드가 존재하고 <code>hsync()</code>는 비용이 더 비싸다. 애플리케이션에서 적절하게 일관성 모델을 정하고 그에 맞게 HDFS의 <code>hflush</code>와 <code>hsync</code>를 활용하여 성능과 데이터 신뢰성을 잘 결정해야 한다.  </p>
<br/>

<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Hadoop-Perfect-Guide-Korean-White/dp/8968484597">https://www.amazon.com/Hadoop-Perfect-Guide-Korean-White/dp/8968484597</a></li>
</ul>
<br/>
<br/>
<br/>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/images/tk-one-profile.jpeg" alt="TK-one"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">TK-one</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, South Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/TK-one/" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/TK-one/"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/OS/"><span class="level-start"><span class="level-item">OS</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/maven/"><span class="level-start"><span class="level-item">maven</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/network/"><span class="level-start"><span class="level-item">network</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/nodejs/"><span class="level-start"><span class="level-item">nodejs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/personal/"><span class="level-start"><span class="level-item">personal</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/tool/"><span class="level-start"><span class="level-item">tool</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0/"><span class="level-start"><span class="level-item">컴퓨터구조</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-19T13:29:02.000Z">2022-06-19</time></p><p class="title"><a href="/2022/06/19/hadoop-file-based-data-structure/">Hadoop 파일기반 자료구조(SequenceFile, MapFile)</a></p><p class="categories"><a href="/categories/Hadoop/">Hadoop</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-18T13:29:02.000Z">2022-06-18</time></p><p class="title"><a href="/2022/06/18/hbase/">HBase 기초</a></p><p class="categories"><a href="/categories/Hadoop/">Hadoop</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-23T13:42:24.000Z">2022-03-23</time></p><p class="title"><a href="/2022/03/23/hadoop-hdfs/">Hadoop HDFS란?</a></p><p class="categories"><a href="/categories/Hadoop/">Hadoop</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-07T13:21:13.000Z">2022-03-07</time></p><p class="title"><a href="/2022/03/07/coronavirus-confirmed/">코로나 확진후기</a></p><p class="categories"><a href="/categories/personal/">personal</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-05T12:59:06.000Z">2022-03-05</time></p><p class="title"><a href="/2022/03/05/how-to-use-markdown/">마크다운(Markdown) 사용법</a></p><p class="categories"><a href="/categories/tool/">tool</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">6월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">3월 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">9월 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">3월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">1월 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">8월 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">7월 2019</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">2월 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">8월 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/OS/"><span class="tag">OS</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/coronavirus/"><span class="tag">coronavirus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/covid19/"><span class="tag">covid19</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/event-loop/"><span class="tag">event-loop</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hadoop/"><span class="tag">hadoop</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hbase/"><span class="tag">hbase</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hdfs/"><span class="tag">hdfs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/markdown/"><span class="tag">markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/maven/"><span class="tag">maven</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nodejs/"><span class="tag">nodejs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/smtp/"><span class="tag">smtp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/thread/"><span class="tag">thread</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0/"><span class="tag">컴퓨터구조</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C/"><span class="tag">파일시스템</span><span class="tag">6</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">업데이트 소식 받기</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="구독"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="기술블로그" height="28"></a><p class="is-size-7"><span>&copy; 2023 TK-one</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv">0</span>명의 사용자가 방문 함</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>